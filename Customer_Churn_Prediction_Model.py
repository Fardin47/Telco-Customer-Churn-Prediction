# -*- coding: utf-8 -*-
"""Fardin_Alam.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_Y7YtiM2DsX9xFzPmGJvh46-qgLboTTv
"""

import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
import numpy as np
from scipy import stats
from datetime import datetime
import os
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import GridSearchCV
from sklearn import metrics
from sklearn.preprocessing import StandardScaler

import lightgbm as lgb
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, StratifiedKFold,GridSearchCV
from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score , accuracy_score
from sklearn.metrics import confusion_matrix, roc_curve, classification_report , auc

from sklearn.metrics import roc_curve, auc
from sklearn.metrics import roc_auc_score

from google.colab import drive
drive.mount('/content/drive')

"""# **Importing Dataset**"""

# Read the Excel file into a DataFrame
file_path = "/content/drive/MyDrive/Telco/Telco_customer_churn.csv"

df = pd.read_csv(file_path)

print("There are {:,} observations and {} columns in the data set.".format(df.shape[0], df.shape[1]))
print("There are {} missing values in the data.".format(df.isna().sum().sum()))

"""# ***Data Cleaning***


"""

# Display basic information about the dataset
print(df.info())

# Display the first few rows of the dataset
print(df.head())

#Display the shape of the data
df.shape

#Changing the datatype of "Total Charges" Column From Object to Numeric as this column contains numeric values.
df['Total Charges'] = pd.to_numeric(df['Total Charges'], errors='coerce')

# Displaying the basic information after applying a change.
print(df.info())

#Looking for the missing values in each columns.
df.isnull().sum()

"""It seems there are 11 and 5174 missing values respectively in "Total Charges" and "Churn Reason" column."""

# Finding out NULL values per column in percentage.
percentage_null_per_column = (df.isnull().sum() / df.shape[0])* 100
percentage_null_per_column

"""Approximately 73.50% of values in the "Churn Reason" column are missing.

"""

# Finding out the reason for 73.50% missing values in the "Churn Reason" column.
plt.figure(figsize=(20, 6))
sns.set_style("whitegrid")


custom_palette = sns.color_palette("Set2")

ax = sns.countplot(data=df, x='Churn Value', palette=custom_palette, order=df['Churn Value'].value_counts().index)

# Rotate x-axis labels for readability
plt.xticks([0, 1], ['Not Churn', 'Churn'])
plt.xticks(rotation=45, fontsize=12)
plt.xlabel('Churn Value', fontsize=14)
plt.ylabel('Number of customers', fontsize=14)
plt.title('Distribution of Churn Customers', fontsize=16)


for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', fontsize=12, color='black', xytext=(0, 5), textcoords='offset points')


ax.yaxis.grid(linestyle='--', alpha=0.7)

# Showing the count plot
plt.tight_layout()
plt.show()

"""From the visualization, It can be observed that there are exact **5174** values are of "Not Churn" customers. Since the customers did not churn, so they would not need to put any reason. So, we do not need to bother with those missing values right now."""

# Now we will handle the missing values in the "Total Charges" column.
# let's take a peak on the 11 rows those are missing.
df[df['Total Charges'].isna()]

# Filling the missing values by calculating the total charges of those columns by multiplying "Tenure Months" (total months that the customer was with the company) with
# "Monthly Charges" (Charge per month) column.
# total charge = per month charge * total months used
mask = pd.isnull(df['Total Charges'])
df.loc[mask, 'Total Charges'] = df['Tenure Months'] * df['Monthly Charges']

# Looking for the rows with 0 value in "Tenure Months" Column.
rows_with_zero_tenure = df[df['Tenure Months'] == 0]
print(rows_with_zero_tenure['CustomerID'])

"""It is noticable that for the Tenure Months of the missing values are all 0. In that case after multiplying all the Total Charges for those rows will be 0. It is understood that they might all be the new customers who have not paid yet."""

#Looking for duplicate values
df.duplicated().sum()

"""No Duplicate Values Found!!"""

#Looking for number of Unique values for each column
df.nunique()

# Look into all the columns in the dataset.
df.columns

# Looking for all the Unique values in Each Columns.
columns = ['CustomerID', 'Count', 'Country', 'State', 'City', 'Zip Code',
       'Lat Long', 'Latitude', 'Longitude', 'Gender', 'Senior Citizen',
       'Partner', 'Dependents', 'Tenure Months', 'Phone Service',
       'Multiple Lines', 'Internet Service', 'Online Security',
       'Online Backup', 'Device Protection', 'Tech Support', 'Streaming TV',
       'Streaming Movies', 'Contract', 'Paperless Billing', 'Payment Method',
       'Monthly Charges', 'Total Charges', 'Churn Label', 'Churn Value',
       'Churn Score', 'CLTV', 'Churn Reason']

def value_cnt(col):
    for i in col:
        print(i,":" ,df[i].unique())
        print("\n")

value_cnt(columns)

# Two values indicating same result in "Multiple Lines" Column such as "No" & "No phone service".
# So, replacing "No phone service" with "No"
df["Multiple Lines"] = df["Multiple Lines"].replace("No phone service", "No")
df['Multiple Lines'].value_counts()

# In several columns, Two values indicating same result such as "No" & "No internet service".
# So, replacing "No internet service" with "No" in all of those colunms.
column_after_replace = ["Online Security" , "Device Protection" , "Online Backup" , "Tech Support" , "Streaming TV" , "Streaming Movies"]

def replace_value(column_after_replace):
    for i in column_after_replace:
        df[i] = df[i].replace("No internet service" , "No")

replace_value(column_after_replace)

# Displaying value counts for each column
for column in column_after_replace:
    print(f"Value counts for {column}:")
    print(df[column].value_counts())
    print("\n")

# Copying the value in another dataframes
df1 = df.copy()
df2 = df.copy()

# Look into all the columns in the dataset.
df1.columns

# Dropping the unnecessary columns.
df1.drop(columns = ["CustomerID" , "Count" ,"Country" , "State" , "City" , "Zip Code" , "Lat Long" , "Latitude" , "Longitude" , "Churn Score" , "Churn Label" ,
                    "CLTV" , "Churn Reason"] , inplace = True , axis = 1)

"""Reason for dropping such columns.
**CustomerID**: As it is an unique identifier, so does not provide any valueable information.
**Count**: simply a count used in reporting/dashboarding, so does not provide any valueable information.
**Country**: Geographic location does not have much influence on customer behavior.
**State**: Same as Country
**City**: Same as Country
**Zip Code**: Same as Country
**Lat Long**: Same as Country
**Latitude**: Same as Country
**Longitude**: Same as Country
**Churn Score**: future information, including them in the model could lead to overfitting
**Churn Label**: Binary indicator of Churn Value
**CLTV**:  future information, including them in the model could lead to overfitting

"""

# Looking into the shape of the dataframe
df1.shape
df1.columns

# # Looking for all the Unique values in Each Columns of df1 dataframe
columns1 = ["Gender" ,"Senior Citizen" ,"Partner" , "Dependents", "Tenure Months" ,"Phone Service" ,"Multiple Lines" ,"Internet Service" ,'Online Security','Online Backup',
          'Device Protection', 'Tech Support','Streaming TV', 'Streaming Movies', 'Contract', 'Paperless Billing','Payment Method', 'Churn Value']

def value_cnt1(col):
    for i in col:
        print(i , "-" ,df1[i].unique())
        print("\n")

value_cnt1(columns1)



"""# ***Explatory Data Analysis & Data Visualization***"""

# Showing the distribution of Churn Label using Percentage.
c = ['green', 'blue']
px.pie(df.groupby('Churn Label')['CustomerID'].count().reset_index(),
       values='CustomerID',
       names='Churn Label',
       color_discrete_sequence=c,
       title='Percentage of Churn Label')

"""So, It is noticeable that, 26.5% of customers are in churn and have already stopped using the services of the company."""

# Creating a count plot
# Calculating the count of each churn reason
churn_reason_counts = df['Churn Reason'].value_counts()

# Sorting the churn reasons by count in descending order
sorted_churn_reasons = churn_reason_counts.index

# Plot information
plt.figure(figsize=(20, 6))
ax = sns.countplot(data=df, x='Churn Reason', order=sorted_churn_reasons, palette='viridis')
plt.xlabel('Churn Reason')
plt.ylabel('Count')
plt.title('Countplot for Churn Reason')
plt.xticks(rotation=90)  # Rotate x-axis labels for readability

# Annotate each bar with its count
for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', fontsize=12, color='black', xytext=(0, 3), textcoords='offset points')

# Show the count plot
plt.show()

# Percentage of Each Churn Reason by Customer Count.
grouped_data = df.groupby(['Churn Reason'])['CustomerID'].count().reset_index()
sorted_data = grouped_data.sort_values('CustomerID', ascending=False)
total_count = sorted_data['CustomerID'].sum()
percentages = (sorted_data['CustomerID'] / total_count) * 100

fig = px.bar(sorted_data, x='Churn Reason', y='CustomerID',
             color='CustomerID', text=percentages,
             color_continuous_scale='Viridis', labels={'CustomerID': 'CustomerID Count'},
             title='Percentage of Each Churn Reasons by Customer Count',
             height=800, width=1600)

fig.update_traces(texttemplate='%{text:.2f}%', textposition='outside')
fig.update_xaxes(tickangle=45)

#Show the figure
fig.show()

"""It can be concluded that,
1. 33.23% of churn customers left due to Competitor made better offer than the company.
2. 17.49% of churn customers left due to bad behavior.
"""

# Plotting the churn rate by tenure
plt.figure(figsize=(12, 6))
sns.lineplot(data=df, x='Tenure Months', y='Churn Value', errorbar=None)
plt.title('Churn Rate by Customer Tenure Months')
plt.xlabel('Tenure Months')
plt.ylabel('Churn Rate')
plt.show()

"""It is evident that customers with a higher churn rate typically leave the service shortly after starting. The longer a user utilizes the service, the lower their churn rate becomes.

# **Geographic Analysis of Churn**
"""

# Finding out customers based on country and state
df.groupby(['Country','State'])['CustomerID'].count()

"""Seems like all the customers are from United States, California."""

# Find out how many cities are the customer from.
df['City'].nunique()

"""The customers are from a total of 1129 cities in US, California."""

# Analyzing a map to understand the impact of geographic location of customers
fig = px.scatter_mapbox(df.groupby(['Latitude','Longitude'])['CustomerID'].count().reset_index(), lat="Latitude", lon="Longitude", hover_data= ['CustomerID'], zoom=4, height=300, opacity = 0.3)
fig.update_layout(mapbox_style="carto-positron")
fig.update_layout(margin={"r":0,"t":0,"l":0,"b":0})
fig.show()

"""By looking into the map, it is observed that most of the customers are from "Los Angeles", "Long Beach", "San Francisco", "San Jose", "Berkeley", etc."""

# Finding out the top 20 cities with largest numbers of customers.
city_customer_count = df.groupby('City')['CustomerID'].count().reset_index().sort_values('CustomerID', ascending=False).head(20)

plt.figure(figsize=(20, 6))
sns.set_style("whitegrid")

# Using a custom color palette
custom_palette = sns.color_palette("Set2")

ax = sns.barplot(x='City', y='CustomerID', data=city_customer_count, palette=custom_palette)

# Rotate x-axis labels for readability
plt.xticks(rotation=45, fontsize=12)
plt.xlabel('City', fontsize=14)
plt.ylabel('Customer Count', fontsize=14)
plt.title('Top 20 Cities with Highest Customer Count', fontsize=16)

# Annotate each bar with its count
for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5), textcoords='offset points')

# Adding grid to the background
ax.yaxis.grid(linestyle='--', alpha=0.7)

# Showing the count plot
plt.tight_layout()
plt.show()

"""So, Los Angeles has the highest customer count with 305.



"""

# Filtering the DataFrame for Churn Value 0 and 1
df_filtered = df[df['Churn Value'].isin([0, 1])]

# Create scatter plot
fig = px.scatter_geo(df_filtered,
                     lat='Latitude',
                     lon='Longitude',
                     color='Churn Value',
                     color_discrete_map={0: 'blue', 1: 'red'},  # Define colors for Churn Value 0 and Churn Value 1
                     hover_data=['City', 'Churn Value'],  # Additional information to display on hover
                     title='Churn Value by Geographic Location', opacity =0.3)

fig.update_traces(marker=dict(size=10, line=dict(width=0.5, color='red')))


# Customize the layout if needed
fig.update_geos(projection_type="natural earth")

# Show the plot
fig.show()

# Filtering the DataFrame for Churn Value == 1 ("Yes")
# This map shows the areas of Churn Customers only.
churn_0_locations = df[df['Churn Value'] == 1].groupby(['Latitude', 'Longitude', 'City'])['CustomerID'].count().reset_index()

fig = px.scatter_mapbox(churn_0_locations,
                        lat="Latitude",
                        lon="Longitude",
                        hover_data=['City'],
                        zoom=4,
                        height=300,
                        opacity=0.3)

fig.update_layout(mapbox_style="carto-positron")
fig.update_layout(margin={"r": 0, "t": 0, "l": 0, "b": 0})
fig.show()

# Top 10 citites with Highest Churn
top_10_churn_cities = df[df['Churn Value'] == 1]['City'].value_counts().head(10).reset_index()

plt.figure(figsize=(12, 6))
sns.set_style("whitegrid")

# Using a custom color palette
custom_palette = sns.color_palette("viridis")

ax = sns.barplot(x='index', y='City', data=top_10_churn_cities, palette=custom_palette)

# Rotate x-axis labels for readability
plt.xticks(rotation=45, fontsize=12)
plt.xlabel('City', fontsize=14)
plt.ylabel('Churn Count', fontsize=14)
plt.title('Top 10 Cities with Highest Churn', fontsize=16)

# Annotate each bar with its count
for p in ax.patches:
    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=12, color='black', xytext=(0, 5), textcoords='offset points')

# Adding grid to the background
ax.yaxis.grid(linestyle='--', alpha=0.7)

# Showing the count plot
plt.tight_layout()
plt.show()

"""Most churns occur in Los Angeles, which is understandable given that the majority of customers are from that area."""

# Filtering data for churned customers
churned_data = df[df['Churn Value'] == 1]

# Create scatter plot with Plotly Express
fig = px.scatter(churned_data, x='Monthly Charges', y='City', color='Churn Value',
                 color_discrete_map={0: 'blue', 1: 'red'}, size_max=10, opacity=0.7,
                 labels={'Monthly Charges': 'Monthly Charges', 'City': 'City'},
                 title='Churn Based on Monthly Charges in Different Cities',
                 template='plotly_white')

# Update layout for better aesthetics
fig.update_layout(showlegend=True, legend_title_text='Churn Value', legend_traceorder='reversed')

# Show the plot
fig.show()

"""High monthly charges correlate with higher churn rates, while low monthly charges are associated with lower churn rates. The number of customer churn is very high when the monthly charge is above 70. So the monthly charge can be a important factor for the customers to churn.

# **Demographic Analysis**
"""

grouped_data = df.groupby(['Gender', 'Senior Citizen', 'Churn Label']).size().reset_index(name='Count')

# Plotting
fig = px.bar(grouped_data, x='Gender', y='Count', color='Senior Citizen', barmode='group',
             facet_col='Churn Label', labels={'Senior Citizen': 'Senior Citizen'}, text='Count')

fig.update_traces(textposition='outside',  # Display text outside the bars
                  texttemplate='%{text}',   # Use the 'text' column for text values
                  )
fig.update_layout(title='Count of Customers by Gender, Senior Citizen, and Churn Status')
fig.show()

"""It is evident that:
1. Both Male and Female non-senior citizens exhibit a total churn of 694 and 699, respectively, demonstrating a nearly similar distribution of churn.
2. Similarly, senior citizen Males and Females show a total churn of 236 and 240, respectively.

In summary, there is a balanced distribution of churn between Male and Female customers, both in the senior citizen and non-senior citizen categories.
"""

# Visualization 1: Churn Value vs Partner
fig1 = px.histogram(df, x='Churn Label', color='Partner', barmode='group', labels={'Churn Label': 'Churn Label'})
fig1.update_layout(title='Churn Label Relationship with Partner Column')

# Visualization 2: Churn Value vs Dependents
fig2 = px.histogram(df, x='Churn Label', color='Dependents', barmode='group', labels={'Churn Label': 'Churn Label'})
fig2.update_layout(title='Churn Label Relationship with Dependents Column')

# Show visualizations
fig1.show()
fig2.show()

"""From the visualization:
1. Churn occurred in 1200 customers without partners and 699 customers with partners.
2. Churn occurred in 1763 customers without any dependents, while only 106 customers with dependents experienced churn. It appears that customers with dependents have a significantly lower churn rate.





"""

# A Tree Map to visualize Churn among Senior Citizen and Gender
demographic_data = df.groupby(['Gender', 'Senior Citizen']).agg({
    'Churn Value': 'mean',
    'CustomerID': 'count'
}).reset_index()

# Rename columns for clarity
demographic_data = demographic_data.rename(columns={'Churn Value': 'Churn Rate', 'CustomerID': 'Customer Count'})

# Creating a treemap to visualize demographic patterns in churn
fig_treemap = px.treemap(demographic_data,
                         path=['Gender', 'Senior Citizen'],
                         values='Customer Count',
                         color='Churn Rate',
                         color_continuous_scale='Viridis',
                         title='Demographic Patterns in Churn for Gender and Senior Citizen',
                         hover_data=['Churn Rate', 'Customer Count'])

fig_treemap.show()

# A tree map to visualize Churn Reasons Based on Senior Citizen and Gender
churned_data = df[df['Churn Value'] == 1]

# Creating a Tree Map
fig = px.treemap(churned_data,
                 path=['Senior Citizen', 'Gender', 'Churn Reason'],
                 values='Churn Value',
                 title='Churn Reasons Based on Senior Citizen and Gender',
                 color='Churn Value')

fig.show()

"""The visualization indicates that Senior Citizen status alone does not significantly influence churn. Instead, non-Senior Citizens are more likely to churn, with distinct reasons for both genders:

**Female Non-Senior Citizens:** Churn reasons include the attitude of support
personnel, competitors offering more data, higher download speeds, and better overall offers.

**Male Non-Senior Citizens**: Churn reasons include the attitude of support personnel, competitors offering higher download speeds, more data, and unknown factors.

This suggests that customer churn is influenced by factors such as customer service, pricing, and product offerings. The pattern holds for Senior Citizens as well, where churn is influenced by attitude, pricing, and product considerations.
"""

import plotly.express as px

# Filter data for churned customers
churned_data_2 = df[df['Churn Value'] == 1]


fig = px.treemap(churned_data_2, path=['Partner', 'Dependents', 'Churn Reason'],
                 values='Churn Value', color='Churn Reason',
                  color_discrete_map={'(?)':'lightgrey', 'Lunch':'gold', 'Dinner':'darkblue'})
fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))
fig.show()

# Filter data for churned customers
churned_data_3 = df[df['Churn Value'] == 1]

# Create a tree map
fig = px.treemap(churned_data_3,
                 path=['Partner', 'Internet Service'],
                 values='Churn Value',
                 title='Churn Value Based on Partner and Internet Service'
                 )

fig.show()

# Filter data for churned customers
churned_data_4 = df[df['Churn Value'] == 1]

# Create a tree map
fig = px.treemap(churned_data_2,
                 path=['Dependents', 'Internet Service'],
                 values='Churn Value',
                 title='Churn Value Based on Dependents and Internet Service'
                 )

fig.show()





"""# **Service Utilization Analysis**"""

# Create density plot using Plotly Express
fig = px.histogram(df, x='Tenure Months', color='Churn Value',
                   marginal='rug',
                   nbins=30,
                   title='Distribution of Tenure between Customers',
                   labels={'Tenure Months': 'Tenure Months', 'Churn Value': 'Churn Value'},
                   color_discrete_map={0: 'blue', 1: 'orange'},
                   opacity=0.7)

fig.show()

"""So we can conclude that,Customers who maintain a longer tenure exhibit a tendency to remain with the company.

"""

# Create Histogram plot for number of customers by contract type
fig = px.histogram(df, x='Contract', color='Contract',
                   title='Number of Customers by Contract Type',
                   labels={'Contract': 'Contract Type', 'count': 'Number of Customers'},
                   color_discrete_map={'Contract': 'Set3'})

fig.show()

fig = px.pie(df.groupby(['Contract','Churn Label'])['CustomerID'].count().reset_index(),
             values='CustomerID',
            names='Contract',
            facet_col = 'Churn Label',
            title = 'Churn rate by contract type')

fig.show()

fig = px.bar(df.groupby(['Internet Service', 'Churn Label'])['CustomerID'].count().reset_index(),
             x='Internet Service',
             y='CustomerID',
             color = 'Churn Label',
             text = 'CustomerID')
fig.show()

"""Most of the customers are connected with Fiber Optic Internet service. Also it is also observed that most of the customers who churned were connected with Fiber Optic Internet service. There might be any internet issue faced by the customers connceted with Fiber Optic internet."""

fig = px.pie(df.groupby(['Internet Service','Churn Label'])['CustomerID'].count().reset_index(),
             values='CustomerID',
            names='Internet Service',
            facet_col = 'Churn Label',
            title = 'Churn rate by Internet Service',color_discrete_sequence=px.colors.sequential.RdBu)

fig.show()

"""69.4% of customers who left were connected to FIber Optic Internet."""

import plotly.express as px

# Filter data for churned customers
churned_data_2 = df[df['Churn Value'] == 1]


fig = px.treemap(churned_data_2, path=['Internet Service', 'Churn Reason'],
                 values='Churn Value', color='Churn Reason',
                  color_discrete_map={'(?)':'lightgrey', 'Lunch':'gold', 'Dinner':'darkblue'})
fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))
fig.show()

"""It can be observed that:
1. Fiber Optic Internet Service users primarily churned due to the support person's attitude and the competitor offering higher download speeds.
2. DSL service customers, in contrast, predominantly churned because the competitor provided higher download speeds and better devices.
"""

# Churn Analysis Based on Internet Service, Tech Support, and Churn Label
fig = px.bar(df.groupby(['Internet Service',
                                                'Tech Support',
                                                'Churn Label'])['CustomerID'].count().reset_index(),
             x="Internet Service",
             y="CustomerID",
             color="Churn Label",
             text = 'CustomerID',
             barmode="group",
             facet_col="Tech Support",color_discrete_sequence=px.colors.sequential.thermal,
             title = "Churn Analysis Based on Internet Service, Tech Support, and Churn Label"
            )
fig.show()

"""It is observed that:
1. Only 196 customers who subscribed to tech support and were connected to Fiber Optic Internet left. In contrast, 1101 customers who did not subscribe to tech support and were connected to Fiber Optic Internet churned. Thus, in this scenario, tech support strongly influences customer churn for Fiber Optic Internet users.
2. For customers connected to DSL internet, a similar trend is observed, where those who subscribed to tech support have a relatively lower likelihood of churning compared to those who did not subscribe to tech support.    
"""

# Churn Analysis Based on Internet Service, Online Security, and Churn Label
fig = px.bar(df.groupby(['Internet Service',
                                                'Online Security',
                                                'Churn Label'])['CustomerID'].count().reset_index(),
             x="Internet Service",
             y="CustomerID",
             color="Churn Label",
             text = 'CustomerID',
             barmode="group",
             facet_col="Online Security",color_discrete_sequence=px.colors.sequential.Plasma,
             title = 'Churn Analysis Based on Internet Service, Online Security, and Churn Label'
            )
fig.show()

# Churn Analysis Based on Internet Service, Online Backup, and Churn Label
fig = px.bar(df.groupby(['Internet Service',
                                                'Online Backup',
                                                'Churn Label'])['CustomerID'].count().reset_index(),
             x="Internet Service",
             y="CustomerID",
             color="Churn Label",
             text = 'CustomerID',
             barmode="group",
             facet_col="Online Backup",color_discrete_sequence=px.colors.sequential.Cividis,
             title = 'Churn Analysis Based on Internet Service, Online Backup, and Churn Label'
            )
fig.show()

# Churn Analysis Based on Payment Method, Internet Service, and Churn Label
fig = px.bar(df.groupby(['Payment Method',
                                                'Internet Service',
                                                'Churn Label'])['CustomerID'].count().reset_index(),
             x="Payment Method",
             y="CustomerID",
             color="Churn Label",
             text = 'CustomerID',
             barmode="group",
             facet_col="Internet Service",color_discrete_sequence=px.colors.sequential.RdBu,
             title = 'Churn Analysis Based on Payment Method, Internet Service, and Churn Label'
            )
fig.show()

"""For Fiber optic Internet customers, the majority chose electronic receipts for payment, and interestingly, this group also has the highest rate of churn."""

# Creating a pie chart to show the Percentage Paymenth Method for each payment method
fig_pie = px.pie(df.groupby(['Payment Method', 'Churn Label'])['CustomerID'].count().reset_index(),
                 names='Churn Label',
                 values='CustomerID',
                 color='Churn Label',
                 facet_col='Payment Method',
                 title='Percentage of Customers by Payment Method and Churn Label',
                 color_discrete_sequence=px.colors.sequential.Magenta)

# Display the pie charts
fig_pie.show()

"""From the pie chart above, it can be concluded that the majority of churned customers, accounting for 45.3%, utilized electronic checks as their payment method."""

# Here I have divided data into groups (low, medium, high) monthly charges
charge_bins = [0, 30, 60, float('inf')]
charge_labels = ['Low', 'Medium', 'High']
df['Charge Group'] = pd.cut(df['Monthly Charges'], bins=charge_bins, labels=charge_labels, right=False)

# Box plot to compare average churn scores in each charge group
fig_box = px.box(df, x='Charge Group', y='Churn Score',
                 title='Comparison of Churn Scores in Different Monthly Charge Groups',
                 template='plotly_white', height=500)
fig_box.show()

"""We can point out 3 observations:
1. Customers in the Low Charge Group are less likely to churn.
2. Customers in the Medium Charge Group are moderately to churn.
3. Customers in the High Charge Group are most likely to churn.
Therefore, Monthly Charges has a decent influence in customers to churn.
"""

# Box plot to visualize the distribution of Monthly Charges for churned and non-churned customers
plt.figure(figsize=(12, 6))
sns.boxplot(x='Churn Value', y='Monthly Charges', data=df)
plt.title('Monthly Charges vs. Churn')
plt.xlabel('Churn Value')
plt.ylabel('Monthly Charges')
plt.show()

# Statistical analysis using t-test or Mann-Whitney U test
from scipy.stats import ttest_ind, mannwhitneyu

churned = df[df['Churn Value'] == 1]['Monthly Charges']
not_churned = df[df['Churn Value'] == 0]['Monthly Charges']

# Perform t-test assuming normal distribution
t_stat, p_value = ttest_ind(churned, not_churned)

# Alternatively, perform Mann-Whitney U test if the assumption of normality is violated
# U_stat, p_value = mannwhitneyu(churned, not_churned)

print(f'T-test p-value: {p_value}')

# Impact of Internet Services on Customer Churn and Monthly Charges for churned customers
churned_data = df[df['Churn Value'] == 1]

# Create a scatter plot to show the impact of Internet Services on Customer Churn and Monthly Charges
fig_scatter = px.scatter(churned_data,
                         x='Monthly Charges',
                         y='Churn Value',
                         color='Internet Service',
                         size='Monthly Charges',
                         labels={'Monthly Charges': 'Monthly Charges', 'Churn Value': 'Churn Value'},
                         size_max=30)

fig_scatter.show()

# Group by Online Security, Tech Support, and Churn Label and calculate the mean Monthly Charges
grouped_data = df.groupby(['Online Security', 'Tech Support', 'Churn Label'])['Monthly Charges'].mean().reset_index()

# Create a bar chart
fig = px.bar(grouped_data,
             x='Online Security',
             y='Monthly Charges',
             color='Churn Label',
             facet_col='Tech Support',
             labels={'Monthly Charges': 'Average Monthly Charges ($)'},
             title='Average Monthly Charges by Online Security and Tech Support')

fig.show()

# Define service combinations
service_combinations = [
    ['Phone Service', 'Multiple Lines'],
    ['Internet Service', 'Online Security', 'Tech Support'],
    ['Internet Service', 'Device Protection', 'Tech Support']
]

# Create charts for each service combination
for services in service_combinations:
    # Group by the selected services and Churn Label and calculate the mean Monthly Charges
    grouped_data = df.groupby(services + ['Churn Label'])['Monthly Charges'].mean().reset_index()

    # Create a bar chart
    fig = px.bar(grouped_data,
                 x=services[0],
                 y='Monthly Charges',
                 color='Churn Label',
                 facet_col=services[1],
                 labels={'Monthly Charges': 'Average Monthly Charges ($)'},
                 title=f'Average Monthly Charges by {", ".join(services)} and Churn Label')

    fig.show()

"""# Data Preprocessing"""

categorical_column = df1.select_dtypes(include = "object")

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

for i in categorical_column:
    df1[i] = le.fit_transform(df1[i])

df1

plt.figure(figsize = (20,10))
sns.heatmap(df1.corr() , annot = True ,linewidths=0.6,linecolor='white' )
plt.show()

"""# MOdel Building"""

df1.groupby('Churn Value')['Churn Value'].count()

from imblearn.over_sampling import SMOTE
over = SMOTE(sampling_strategy = 1)

x = df1.drop("Churn Value", axis = 1).values
y = df1['Churn Value'].values

x,y = over.fit_resample(x,y)

X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=2)

"""## Logistic Regression"""



logisticRegr = LogisticRegression(C=0.1)

logisticRegr.fit(X_train, y_train)

#Train data accuracy-
logisticRegr_X_train_Prediction = logisticRegr.predict(X_train)
logisticRegr_training_data_accuracy = accuracy_score(logisticRegr_X_train_Prediction, y_train)*100

print('Training Data Accuracy of Logistic Regression:' ,logisticRegr_training_data_accuracy)

Y_pred_logisticRegr = logisticRegr.predict(X_test)

#Test Accuracy
logisticRegr_test_data_accuracy = accuracy_score(y_test, Y_pred_logisticRegr)*100

print('Testing Data Accuracy of Logistic Regression:', logisticRegr_test_data_accuracy)

# Performing cross-validation
cv_scores = cross_val_score(logisticRegr, X_train, y_train, cv=5, scoring='roc_auc', n_jobs=-1)

# Print the cross-validated scores and MEAN ROC AUC
print("Cross-validated ROC AUC scores:", cv_scores)
print("Mean ROC AUC:", cv_scores.mean())

#Evaluation parameters = precision and recall and F1 SCore

#Precision
print(precision_score(y_test, Y_pred_logisticRegr))

#Recall
print(recall_score(y_test, Y_pred_logisticRegr))

#F1 score
print(f1_score(y_test, Y_pred_logisticRegr))

#Classification report
print(classification_report(y_test, Y_pred_logisticRegr))

#ROC AUC Curve
fpr, tpr, _ = metrics.roc_curve(y_test,  logisticRegr.predict_proba(X_test)[:, 1])
auc_log = metrics.roc_auc_score(y_test, logisticRegr.predict_proba(X_test)[:, 1])

plt.plot(fpr,tpr,label="AUC="+str(auc_log))
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.title('ROC Curve for logistic Regression')
plt.legend(loc=4)
plt.show()

# Generating Confusion Matrix for Logistic Regression
cf_matrix_LR = confusion_matrix(y_test, Y_pred_logisticRegr)

print(cf_matrix_LR)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix_LR.flatten()]

group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix_LR.flatten()/np.sum(cf_matrix_LR)]

labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]

labels = np.asarray(labels).reshape(2,2)

ax = sns.heatmap(cf_matrix_LR, annot=labels, fmt='', cmap='Blues')

ax.set_title('Seaborn Confusion Matrix for Logistic Regression\n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

# Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['False','True'])
ax.yaxis.set_ticklabels(['False','True'])

# Display the visualization of the Confusion Matrix.
plt.show()

"""## Random Forest"""

#USING HYPERPARAMETERS

#RANDOM FOREST

# Number of trees in random forest
n_estimators = [int(x) for x in np.linspace(start = 10, stop = 80, num = 10)]
# Number of features to consider at every split
max_features = ['auto', 'sqrt']
# Maximum number of levels in tree
max_depth = [2,4]
# Minimum number of samples required to split a node
min_samples_split = [2, 5]
# Minimum number of samples required at each leaf node
min_samples_leaf = [1, 2]
# Method of selecting samples for training each tree
bootstrap = [True, False]


# Create the param grid
param_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap}
print(param_grid)



rf_Model = RandomForestClassifier()

rf_Grid = GridSearchCV(estimator = rf_Model, param_grid = param_grid, cv = 3, verbose=2, n_jobs = 4)

rf_Grid.fit(X_train, y_train)

# Train Data Accuracy
rfgrid_X_train_Prediction = rf_Grid.predict(X_train)
rfgrid_training_data_accuracy = accuracy_score(rfgrid_X_train_Prediction, y_train)*100

print('Training Data Accuracy of Random Forest:' ,rfgrid_training_data_accuracy)

y_pred_RandomForestGrid = rf_Grid.predict(X_test)
#Test Data Accuracy
print('Testing Data Accuracy of Random Forest:' ,accuracy_score(y_pred_RandomForestGrid,y_test))
print(rf_Grid.best_params_)

# Performing cross-validation
cv_scores = cross_val_score(rf_Model, X_train, y_train, cv=5, scoring='roc_auc', n_jobs=-1)

# Print the cross-validated scores and MEAN ROC AUC
print("Cross-validated ROC AUC scores:", cv_scores)
print("Mean ROC AUC:", cv_scores.mean())

#Evaluation parameters = precision and recall and F1 SCore

#Precision
print(precision_score(y_test, y_pred_RandomForestGrid))

#Recall
print(recall_score(y_test, y_pred_RandomForestGrid))

#F1 score
print(f1_score(y_test, y_pred_RandomForestGrid))

#Classification report
print(classification_report(y_test, y_pred_RandomForestGrid))

# ROC AUC Curve for Random Forest
fpr, tpr, _ = metrics.roc_curve(y_test,  rf_Grid.predict_proba(X_test)[:, 1])
auc_log = metrics.roc_auc_score(y_test, rf_Grid.predict_proba(X_test)[:, 1])

plt.plot(fpr,tpr,label="AUC="+str(auc_log))
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.title('ROC Curve for Random Forest')
plt.legend(loc=4)
plt.show()

# Confusion Matrix for Random Forest
cf_matrix_RF = confusion_matrix(y_test, y_pred_RandomForestGrid)

print(cf_matrix_RF)

group_names = ['True Neg','False Pos','False Neg','True Pos']

group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix_RF.flatten()]

group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix_RF.flatten()/np.sum(cf_matrix_RF)]

labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]

labels = np.asarray(labels).reshape(2,2)

ax = sns.heatmap(cf_matrix_RF, annot=labels, fmt='', cmap='Blues')

ax.set_title('Seaborn Confusion Matrix Random Forest\n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['False','True'])
ax.yaxis.set_ticklabels(['False','True'])

## Display the visualization of the Confusion Matrix.
plt.show()

"""## Light Gradient Boosting"""

gbm = lgb.LGBMClassifier(class_weight='balanced', random_state=92)

# Parameter tuning
grid = {'boosting_type': ['gbdt', 'dart'],
        'num_leaves': [int(x) for x in np.linspace(start = 20, stop = 50, num = 7)],
        'max_depth' : [-1, 3, 7, 14, 21],
        'learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.5, 1],
        'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 500, num = 5)],
        'min_split_gain': [0.00001, 0.0001, 0.001, 0.01, 0.1],
        'min_child_samples': [3, 5, 7],
        'subsample': [0.5, 0.8, 0.95],
        'colsample_bytree': [0.6, 0.75, 1]}

gbm_cv=RandomizedSearchCV(estimator=gbm, param_distributions=grid, scoring='roc_auc',
                         n_iter=100, cv=5, random_state=92, n_jobs=-1)

gbm_cv.fit(X_train, y_train)

# Best params
gbm = gbm_cv.best_estimator_
y_train_gbm = gbm.predict(X_train)

#Train Data Accuracy
print('Training data accuracy of lgbm:' , accuracy_score(y_train, y_train_gbm))


y_pred_gbm = gbm.predict(X_test)

#Test Data Accuracy
print('Testing data accuracy of lgbm' ,accuracy_score(y_test, y_pred_gbm))

# Performing cross-validation
cv_scores = cross_val_score(gbm, X_train, y_train, cv=5, scoring='roc_auc', n_jobs=-1)

# Print the cross-validated scores and MEAN ROC AUC
print("Cross-validated ROC AUC scores:", cv_scores)
print("Mean ROC AUC:", cv_scores.mean())

#Evaluation parameters = precision and recall and F1 SCore

#Precision
print(precision_score(y_test, y_pred_gbm))

#Recall
print(recall_score(y_test, y_pred_gbm))

#F1 score
print(f1_score(y_test, y_pred_gbm))

#Classification report
print(classification_report(y_test, y_pred_gbm))

# ROC AUC Curve For LGBM
fpr, tpr, _ = metrics.roc_curve(y_test,  gbm.predict_proba(X_test)[:, 1])
auc_log = metrics.roc_auc_score(y_test, gbm.predict_proba(X_test)[:, 1])

plt.plot(fpr,tpr,label="AUC="+str(auc_log))
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.title('ROC Curve for LGBM')
plt.legend(loc=4)
plt.show()

#Confusion Matrix for LGBM
cf_matrix_gbm = confusion_matrix(y_test, y_pred_gbm)

print(cf_matrix_gbm)

group_names = ['True Neg','False Pos','False Neg','True Pos']

group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix_gbm.flatten()]

group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix_gbm.flatten()/np.sum(cf_matrix_gbm)]

labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]

labels = np.asarray(labels).reshape(2,2)

ax = sns.heatmap(cf_matrix_gbm, annot=labels, fmt='', cmap='Blues')

ax.set_title('Seaborn Confusion Matrix for LGBM\n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['False','True'])
ax.yaxis.set_ticklabels(['False','True'])

## Display the visualization of the Confusion Matrix.
plt.show()

"""## XGBoost Classifier"""

#XGBOOST

param_grid = dict(
    n_estimators=stats.randint(10, 1000),
    max_depth=stats.randint(1, 10),
    learning_rate=stats.uniform(0, 1)
)

xgb_clf = XGBClassifier(use_label_encoder=False)
xgb_cv = RandomizedSearchCV(
    xgb_clf, param_grid, cv=3, n_iter=50,
    scoring='accuracy', n_jobs=-1, verbose=1
)
xgb_cv.fit(X_train, y_train)
best_params = xgb_cv.best_params_
print(f"Best paramters: {best_params}")

xgb_clf = XGBClassifier(**best_params)
xgb_clf.fit(X_train, y_train)

y_train_xgb_clf = xgb_clf.predict(X_train)
#Train Data Accuracy
print('Training data accuracy of xgboost: ' , accuracy_score(y_train, y_train_xgb_clf)*100)

y_pred_xgb_clf = xgb_clf.predict(X_test)
# Test Data Accuracy
print("Testing data accuracy of xgboost: ", accuracy_score(y_test, y_pred_xgb_clf)*100)

# Performing cross-validation
cv_scores = cross_val_score(xgb_clf, X_train, y_train, cv=5, scoring='roc_auc', n_jobs=-1)

# Print the cross-validated scores and MEAN ROC AUC
print("Cross-validated ROC AUC scores:", cv_scores)
print("Mean ROC AUC:", cv_scores.mean())

#Evaluation parameters = precision and recall and F1 SCore

#Precision
print(precision_score(y_test, y_pred_xgb_clf))

#Recall
print(recall_score(y_test, y_pred_xgb_clf))

#F1 score
print(f1_score(y_test, y_pred_xgb_clf))

#Classification report
print(classification_report(y_test, y_pred_xgb_clf))

#ROC AUC Curve for XGBoost
fpr, tpr, _ = metrics.roc_curve(y_test,  xgb_clf.predict_proba(X_test)[:, 1])
auc_log = metrics.roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])

plt.plot(fpr,tpr,label="AUC="+str(auc_log))
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.title('ROC Curve for XGBoost')
plt.legend(loc=4)
plt.show()

#Confusion Matrix for XGBoost
cf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb_clf)

print(cf_matrix_xgb)

group_names = ['True Neg','False Pos','False Neg','True Pos']

group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix_xgb.flatten()]

group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix_xgb.flatten()/np.sum(cf_matrix_xgb)]

labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]

labels = np.asarray(labels).reshape(2,2)

ax = sns.heatmap(cf_matrix_xgb, annot=labels, fmt='', cmap='Blues')

ax.set_title('Seaborn Confusion Matrix for XGBoost\n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['False','True'])
ax.yaxis.set_ticklabels(['False','True'])

## Display the visualization of the Confusion Matrix.
plt.show()

"""# Interpreting the results:
I developed 4 models and these are Logistic Regression, Random Forest, LGBM Classfier and XGBoost Classifier.
Among these 4 models, LGBM Classifier and XGBoost Classifier both performed quite well than LR and RF.
But, I will be selecting XGBoost Classifier for the churn Prediction Model. So, I am only interpreting the result of XGBoost Classifier.

Therefore, we got,

**Training data accuracy of XGBoost: 88.78%**
This training data accuracy suggesting that the model performs well on the
training data.

**Testing data accuracy of xgboost: 87.00%**
Even if the testing data accuracy is slightly lower than train data accuracy, still it can be conclude that the model is generalizig well.

Mean ROC AUC: 0.94
ROC is basically a probability curve which plots True-Positive Rate against False-Positive Rate at various thresholds of the same model. An AUC value closer to 1 indicates good discrimination. A value of 0.94 is excellent and suggests that the model performs well in terms of classification.

Precision: 0.87
Precision measures that among the cases predicted to be positive, how much percentage of them are really positive. In this model, 87% of the instances as predicted as positive are true positives. So, it is quite good.

Recall: 0.87
Recall measures how much percentage of real positive cases are correctly identified. In this model, 87% of the actual positive instances are correctly identified.


F1-Score: 0.87
It is the mean of Precison and Recall. So, 87% concludes that there is a decent balance between precision and recall.

**Insights on model performance:**

1.The XGBoost model shows high performance across all the evaluation metrics.
2.High ROC AUC indicates outstanding discrimination ability.
3.Precision, recall, and F1-score are well-balanced, suggesting a strong model.
4.The model performs well on the testing dataset, as shown by the almost similar training and testing accuracies.

# **Deployment Plan**
We can develop a Web Based Application named "Churn Prediction Model System" that will predict which customers are most likely to churn.
Churn Prediction Model System:
Churn Prediction Model System helps to predict the customer those are most likely to churn. This system will help telco company's to predict their customer churn. Telco company can design many web pages according to their need and preference. However, a basic deployment plan is given below.

Deployment steps:
1. Environment Setup: Set up Python and Django Framework for the production environment. Use SQLite or MySQL database for storing necessary information.
2. Djano Application Setup:  Define Django models, views, and templates as needed for your application. In views, a function dedicated to handling churn predictions. In Templates, build a interactive web page using HTML, CSS and Javascript. In Models, define all the entities and attributes that will be used in this system.
3. Test Scalability: Make sure this Django application can handle an expected volume of requests.
4. Security: Implement appropriate security measures, including secure communication (HTTPS), and user authentication.
5. Documentation: A user documentation will guide the users to interact with the system appropriately.

Monitoring and Maintaing:
1. Contniously monitor the application's performance  
2. Identify any potential issues.
3. Need to perform continuous testing of the web application.
4. Implement a way to gather user feedback, it will help to understand about what type of problems users are facing.
5. Keep the application up to date and continuously monitor and fix any bugs arises.
"""

